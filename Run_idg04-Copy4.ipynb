{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.optimizers import rmsprop, adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dataset_dir = Path(r\"C:/Users/user/OneDrive/python3/aminomap/Amyloid_prediction/2D_Dataset/train/Image/Rotate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(width, height)=(6,6)\n",
    "\n",
    "def load_dataset(dataset_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    names=[]\n",
    "\n",
    "    for sub_dir in dataset_dir.iterdir():\n",
    "        for img_path in sub_dir.iterdir():\n",
    "            img = (Image.open(img_path))\n",
    "            img = img.resize((width, height)) #ファイルサイズが294×294　→ 6×6に変換\n",
    "\n",
    "            img = np.array(img) #イメージデータをnp.arrayに変換\n",
    "            label = sub_dir.name #ディレクトリ名をラベルにする\n",
    "\n",
    "            file_names = os.path.basename(img_path)\n",
    "            \n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "            names.append(file_names)\n",
    "\n",
    "    return np.array(data), np.array(labels), np.array(names) #np.arrayのデータとラベルを作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,n = load_dataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 6, 6, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['180_matrix_One_0.png', '180_matrix_One_10.png',\n",
       "       '180_matrix_One_12.png', '180_matrix_One_13.png',\n",
       "       '180_matrix_One_15.png', '180_matrix_One_19.png',\n",
       "       '180_matrix_One_2.png', '180_matrix_One_20.png',\n",
       "       '180_matrix_One_21.png', '180_matrix_One_22.png',\n",
       "       '180_matrix_One_23.png', '180_matrix_One_25.png',\n",
       "       '180_matrix_One_26.png', '180_matrix_One_27.png',\n",
       "       '180_matrix_One_3.png', '180_matrix_One_30.png',\n",
       "       '180_matrix_One_31.png', '180_matrix_One_32.png',\n",
       "       '180_matrix_One_33.png', '180_matrix_One_34.png',\n",
       "       '180_matrix_One_35.png', '180_matrix_One_37.png',\n",
       "       '180_matrix_One_39.png', '180_matrix_One_4.png',\n",
       "       '180_matrix_One_41.png', '180_matrix_One_42.png',\n",
       "       '180_matrix_One_44.png', '180_matrix_One_48.png',\n",
       "       '180_matrix_One_49.png', '180_matrix_One_5.png',\n",
       "       '180_matrix_One_50.png', '180_matrix_One_54.png',\n",
       "       '180_matrix_One_55.png', '180_matrix_One_56.png',\n",
       "       '180_matrix_One_57.png', '180_matrix_One_58.png',\n",
       "       '180_matrix_One_59.png', '180_matrix_One_6.png',\n",
       "       '180_matrix_One_62.png', '180_matrix_One_63.png',\n",
       "       '180_matrix_One_64.png', '180_matrix_One_65.png',\n",
       "       '180_matrix_One_66.png', '180_matrix_One_69.png',\n",
       "       '180_matrix_One_7.png', '180_matrix_One_71.png',\n",
       "       '180_matrix_One_72.png', '180_matrix_One_73.png',\n",
       "       '180_matrix_One_74.png', '180_matrix_One_75.png',\n",
       "       '180_matrix_One_76.png', '180_matrix_One_77.png',\n",
       "       '180_matrix_One_78.png', '180_matrix_One_8.png',\n",
       "       '180_matrix_One_80.png', '180_matrix_One_81.png',\n",
       "       '180_matrix_One_83.png', '180_matrix_One_84.png',\n",
       "       '180_matrix_One_85.png', '180_matrix_One_86.png',\n",
       "       '180_matrix_One_88.png', '180_matrix_One_89.png',\n",
       "       '180_matrix_One_90.png', '180_matrix_One_92.png',\n",
       "       '180_matrix_One_93.png', '180_matrix_One_94.png',\n",
       "       '180_matrix_One_95.png', '180_matrix_One_96.png',\n",
       "       '180_matrix_One_97.png', '180_matrix_One_98.png',\n",
       "       '180_matrix_One_99.png', '270_matrix_One_0.png',\n",
       "       '270_matrix_One_10.png', '270_matrix_One_12.png',\n",
       "       '270_matrix_One_13.png', '270_matrix_One_15.png',\n",
       "       '270_matrix_One_19.png', '270_matrix_One_2.png',\n",
       "       '270_matrix_One_20.png', '270_matrix_One_21.png',\n",
       "       '270_matrix_One_22.png', '270_matrix_One_23.png',\n",
       "       '270_matrix_One_25.png', '270_matrix_One_26.png',\n",
       "       '270_matrix_One_27.png', '270_matrix_One_3.png',\n",
       "       '270_matrix_One_30.png', '270_matrix_One_31.png',\n",
       "       '270_matrix_One_32.png', '270_matrix_One_33.png',\n",
       "       '270_matrix_One_34.png', '270_matrix_One_35.png',\n",
       "       '270_matrix_One_37.png', '270_matrix_One_39.png',\n",
       "       '270_matrix_One_4.png', '270_matrix_One_41.png',\n",
       "       '270_matrix_One_42.png', '270_matrix_One_44.png',\n",
       "       '270_matrix_One_48.png', '270_matrix_One_49.png',\n",
       "       '270_matrix_One_5.png', '270_matrix_One_50.png',\n",
       "       '270_matrix_One_54.png', '270_matrix_One_55.png',\n",
       "       '270_matrix_One_56.png', '270_matrix_One_57.png',\n",
       "       '270_matrix_One_58.png', '270_matrix_One_59.png',\n",
       "       '270_matrix_One_6.png', '270_matrix_One_62.png',\n",
       "       '270_matrix_One_63.png', '270_matrix_One_64.png',\n",
       "       '270_matrix_One_65.png', '270_matrix_One_66.png',\n",
       "       '270_matrix_One_69.png', '270_matrix_One_7.png',\n",
       "       '270_matrix_One_71.png', '270_matrix_One_72.png',\n",
       "       '270_matrix_One_73.png', '270_matrix_One_74.png',\n",
       "       '270_matrix_One_75.png', '270_matrix_One_76.png',\n",
       "       '270_matrix_One_77.png', '270_matrix_One_78.png',\n",
       "       '270_matrix_One_8.png', '270_matrix_One_80.png',\n",
       "       '270_matrix_One_81.png', '270_matrix_One_83.png',\n",
       "       '270_matrix_One_84.png', '270_matrix_One_85.png',\n",
       "       '270_matrix_One_86.png', '270_matrix_One_88.png',\n",
       "       '270_matrix_One_89.png', '270_matrix_One_90.png',\n",
       "       '270_matrix_One_92.png', '270_matrix_One_93.png',\n",
       "       '270_matrix_One_94.png', '270_matrix_One_95.png',\n",
       "       '270_matrix_One_96.png', '270_matrix_One_97.png',\n",
       "       '270_matrix_One_98.png', '270_matrix_One_99.png',\n",
       "       '90_matrix_One_0.png', '90_matrix_One_10.png',\n",
       "       '90_matrix_One_12.png', '90_matrix_One_13.png',\n",
       "       '90_matrix_One_15.png', '90_matrix_One_19.png',\n",
       "       '90_matrix_One_2.png', '90_matrix_One_20.png',\n",
       "       '90_matrix_One_21.png', '90_matrix_One_22.png',\n",
       "       '90_matrix_One_23.png', '90_matrix_One_25.png',\n",
       "       '90_matrix_One_26.png', '90_matrix_One_27.png',\n",
       "       '90_matrix_One_3.png', '90_matrix_One_30.png',\n",
       "       '90_matrix_One_31.png', '90_matrix_One_32.png',\n",
       "       '90_matrix_One_33.png', '90_matrix_One_34.png',\n",
       "       '90_matrix_One_35.png', '90_matrix_One_37.png',\n",
       "       '90_matrix_One_39.png', '90_matrix_One_4.png',\n",
       "       '90_matrix_One_41.png', '90_matrix_One_42.png',\n",
       "       '90_matrix_One_44.png', '90_matrix_One_48.png',\n",
       "       '90_matrix_One_49.png', '90_matrix_One_5.png',\n",
       "       '90_matrix_One_50.png', '90_matrix_One_54.png',\n",
       "       '90_matrix_One_55.png', '90_matrix_One_56.png',\n",
       "       '90_matrix_One_57.png', '90_matrix_One_58.png',\n",
       "       '90_matrix_One_59.png', '90_matrix_One_6.png',\n",
       "       '90_matrix_One_62.png', '90_matrix_One_63.png',\n",
       "       '90_matrix_One_64.png', '90_matrix_One_65.png',\n",
       "       '90_matrix_One_66.png', '90_matrix_One_69.png',\n",
       "       '90_matrix_One_7.png', '90_matrix_One_71.png',\n",
       "       '90_matrix_One_72.png', '90_matrix_One_73.png',\n",
       "       '90_matrix_One_74.png', '90_matrix_One_75.png',\n",
       "       '90_matrix_One_76.png', '90_matrix_One_77.png',\n",
       "       '90_matrix_One_78.png', '90_matrix_One_8.png',\n",
       "       '90_matrix_One_80.png', '90_matrix_One_81.png',\n",
       "       '90_matrix_One_83.png', '90_matrix_One_84.png',\n",
       "       '90_matrix_One_85.png', '90_matrix_One_86.png',\n",
       "       '90_matrix_One_88.png', '90_matrix_One_89.png',\n",
       "       '90_matrix_One_90.png', '90_matrix_One_92.png',\n",
       "       '90_matrix_One_93.png', '90_matrix_One_94.png',\n",
       "       '90_matrix_One_95.png', '90_matrix_One_96.png',\n",
       "       '90_matrix_One_97.png', '90_matrix_One_98.png',\n",
       "       '90_matrix_One_99.png', 'matrix_One_0.png', 'matrix_One_10.png',\n",
       "       'matrix_One_12.png', 'matrix_One_13.png', 'matrix_One_15.png',\n",
       "       'matrix_One_19.png', 'matrix_One_2.png', 'matrix_One_20.png',\n",
       "       'matrix_One_21.png', 'matrix_One_22.png', 'matrix_One_23.png',\n",
       "       'matrix_One_25.png', 'matrix_One_26.png', 'matrix_One_27.png',\n",
       "       'matrix_One_3.png', 'matrix_One_30.png', 'matrix_One_31.png',\n",
       "       'matrix_One_32.png', 'matrix_One_33.png', 'matrix_One_34.png',\n",
       "       'matrix_One_35.png', 'matrix_One_37.png', 'matrix_One_39.png',\n",
       "       'matrix_One_4.png', 'matrix_One_41.png', 'matrix_One_42.png',\n",
       "       'matrix_One_44.png', 'matrix_One_48.png', 'matrix_One_49.png',\n",
       "       'matrix_One_5.png', 'matrix_One_50.png', 'matrix_One_54.png',\n",
       "       'matrix_One_55.png', 'matrix_One_56.png', 'matrix_One_57.png',\n",
       "       'matrix_One_58.png', 'matrix_One_59.png', 'matrix_One_6.png',\n",
       "       'matrix_One_62.png', 'matrix_One_63.png', 'matrix_One_64.png',\n",
       "       'matrix_One_65.png', 'matrix_One_66.png', 'matrix_One_69.png',\n",
       "       'matrix_One_7.png', 'matrix_One_71.png', 'matrix_One_72.png',\n",
       "       'matrix_One_73.png', 'matrix_One_74.png', 'matrix_One_75.png',\n",
       "       'matrix_One_76.png', 'matrix_One_77.png', 'matrix_One_78.png',\n",
       "       'matrix_One_8.png', 'matrix_One_80.png', 'matrix_One_81.png',\n",
       "       'matrix_One_83.png', 'matrix_One_84.png', 'matrix_One_85.png',\n",
       "       'matrix_One_86.png', 'matrix_One_88.png', 'matrix_One_89.png',\n",
       "       'matrix_One_90.png', 'matrix_One_92.png', 'matrix_One_93.png',\n",
       "       'matrix_One_94.png', 'matrix_One_95.png', 'matrix_One_96.png',\n",
       "       'matrix_One_97.png', 'matrix_One_98.png', 'matrix_One_99.png',\n",
       "       '180_matrix_Zero_1.png', '180_matrix_Zero_100.png',\n",
       "       '180_matrix_Zero_101.png', '180_matrix_Zero_102.png',\n",
       "       '180_matrix_Zero_103.png', '180_matrix_Zero_104.png',\n",
       "       '180_matrix_Zero_105.png', '180_matrix_Zero_106.png',\n",
       "       '180_matrix_Zero_107.png', '180_matrix_Zero_108.png',\n",
       "       '180_matrix_Zero_109.png', '180_matrix_Zero_112.png',\n",
       "       '180_matrix_Zero_113.png', '180_matrix_Zero_115.png',\n",
       "       '180_matrix_Zero_118.png', '180_matrix_Zero_119.png',\n",
       "       '180_matrix_Zero_120.png', '180_matrix_Zero_121.png',\n",
       "       '180_matrix_Zero_122.png', '180_matrix_Zero_123.png',\n",
       "       '180_matrix_Zero_124.png', '180_matrix_Zero_125.png',\n",
       "       '180_matrix_Zero_126.png', '180_matrix_Zero_13.png',\n",
       "       '180_matrix_Zero_130.png', '180_matrix_Zero_133.png',\n",
       "       '180_matrix_Zero_134.png', '180_matrix_Zero_135.png',\n",
       "       '180_matrix_Zero_14.png', '180_matrix_Zero_15.png',\n",
       "       '180_matrix_Zero_16.png', '180_matrix_Zero_17.png',\n",
       "       '180_matrix_Zero_18.png', '180_matrix_Zero_2.png',\n",
       "       '180_matrix_Zero_20.png', '180_matrix_Zero_21.png',\n",
       "       '180_matrix_Zero_22.png', '180_matrix_Zero_23.png',\n",
       "       '180_matrix_Zero_24.png', '180_matrix_Zero_25.png',\n",
       "       '180_matrix_Zero_26.png', '180_matrix_Zero_27.png',\n",
       "       '180_matrix_Zero_3.png', '180_matrix_Zero_30.png',\n",
       "       '180_matrix_Zero_31.png', '180_matrix_Zero_32.png',\n",
       "       '180_matrix_Zero_33.png', '180_matrix_Zero_35.png',\n",
       "       '180_matrix_Zero_37.png', '180_matrix_Zero_38.png',\n",
       "       '180_matrix_Zero_39.png', '180_matrix_Zero_4.png',\n",
       "       '180_matrix_Zero_41.png', '180_matrix_Zero_42.png',\n",
       "       '180_matrix_Zero_43.png', '180_matrix_Zero_45.png',\n",
       "       '180_matrix_Zero_46.png', '180_matrix_Zero_47.png',\n",
       "       '180_matrix_Zero_48.png', '180_matrix_Zero_50.png',\n",
       "       '180_matrix_Zero_51.png', '180_matrix_Zero_52.png',\n",
       "       '180_matrix_Zero_53.png', '180_matrix_Zero_54.png',\n",
       "       '180_matrix_Zero_55.png', '180_matrix_Zero_56.png',\n",
       "       '180_matrix_Zero_57.png', '180_matrix_Zero_58.png',\n",
       "       '180_matrix_Zero_6.png', '180_matrix_Zero_61.png',\n",
       "       '180_matrix_Zero_65.png', '180_matrix_Zero_66.png',\n",
       "       '180_matrix_Zero_67.png', '180_matrix_Zero_68.png',\n",
       "       '180_matrix_Zero_69.png', '180_matrix_Zero_7.png',\n",
       "       '180_matrix_Zero_71.png', '180_matrix_Zero_74.png',\n",
       "       '180_matrix_Zero_77.png', '180_matrix_Zero_78.png',\n",
       "       '180_matrix_Zero_79.png', '180_matrix_Zero_80.png',\n",
       "       '180_matrix_Zero_82.png', '180_matrix_Zero_84.png',\n",
       "       '180_matrix_Zero_85.png', '180_matrix_Zero_86.png',\n",
       "       '180_matrix_Zero_88.png', '180_matrix_Zero_89.png',\n",
       "       '180_matrix_Zero_9.png', '180_matrix_Zero_90.png',\n",
       "       '180_matrix_Zero_91.png', '180_matrix_Zero_94.png',\n",
       "       '180_matrix_Zero_96.png', '180_matrix_Zero_97.png',\n",
       "       '180_matrix_Zero_98.png', '180_matrix_Zero_99.png',\n",
       "       '270_matrix_Zero_1.png', '270_matrix_Zero_100.png',\n",
       "       '270_matrix_Zero_101.png', '270_matrix_Zero_102.png',\n",
       "       '270_matrix_Zero_103.png', '270_matrix_Zero_104.png',\n",
       "       '270_matrix_Zero_105.png', '270_matrix_Zero_106.png',\n",
       "       '270_matrix_Zero_107.png', '270_matrix_Zero_108.png',\n",
       "       '270_matrix_Zero_109.png', '270_matrix_Zero_112.png',\n",
       "       '270_matrix_Zero_113.png', '270_matrix_Zero_115.png',\n",
       "       '270_matrix_Zero_118.png', '270_matrix_Zero_119.png',\n",
       "       '270_matrix_Zero_120.png', '270_matrix_Zero_121.png',\n",
       "       '270_matrix_Zero_122.png', '270_matrix_Zero_123.png',\n",
       "       '270_matrix_Zero_124.png', '270_matrix_Zero_125.png',\n",
       "       '270_matrix_Zero_126.png', '270_matrix_Zero_13.png',\n",
       "       '270_matrix_Zero_130.png', '270_matrix_Zero_133.png',\n",
       "       '270_matrix_Zero_134.png', '270_matrix_Zero_135.png',\n",
       "       '270_matrix_Zero_14.png', '270_matrix_Zero_15.png',\n",
       "       '270_matrix_Zero_16.png', '270_matrix_Zero_17.png',\n",
       "       '270_matrix_Zero_18.png', '270_matrix_Zero_2.png',\n",
       "       '270_matrix_Zero_20.png', '270_matrix_Zero_21.png',\n",
       "       '270_matrix_Zero_22.png', '270_matrix_Zero_23.png',\n",
       "       '270_matrix_Zero_24.png', '270_matrix_Zero_25.png',\n",
       "       '270_matrix_Zero_26.png', '270_matrix_Zero_27.png',\n",
       "       '270_matrix_Zero_3.png', '270_matrix_Zero_30.png',\n",
       "       '270_matrix_Zero_31.png', '270_matrix_Zero_32.png',\n",
       "       '270_matrix_Zero_33.png', '270_matrix_Zero_35.png',\n",
       "       '270_matrix_Zero_37.png', '270_matrix_Zero_38.png',\n",
       "       '270_matrix_Zero_39.png', '270_matrix_Zero_4.png',\n",
       "       '270_matrix_Zero_41.png', '270_matrix_Zero_42.png',\n",
       "       '270_matrix_Zero_43.png', '270_matrix_Zero_45.png',\n",
       "       '270_matrix_Zero_46.png', '270_matrix_Zero_47.png',\n",
       "       '270_matrix_Zero_48.png', '270_matrix_Zero_50.png',\n",
       "       '270_matrix_Zero_51.png', '270_matrix_Zero_52.png',\n",
       "       '270_matrix_Zero_53.png', '270_matrix_Zero_54.png',\n",
       "       '270_matrix_Zero_55.png', '270_matrix_Zero_56.png',\n",
       "       '270_matrix_Zero_57.png', '270_matrix_Zero_58.png',\n",
       "       '270_matrix_Zero_6.png', '270_matrix_Zero_61.png',\n",
       "       '270_matrix_Zero_65.png', '270_matrix_Zero_66.png',\n",
       "       '270_matrix_Zero_67.png', '270_matrix_Zero_68.png',\n",
       "       '270_matrix_Zero_69.png', '270_matrix_Zero_7.png',\n",
       "       '270_matrix_Zero_71.png', '270_matrix_Zero_74.png',\n",
       "       '270_matrix_Zero_77.png', '270_matrix_Zero_78.png',\n",
       "       '270_matrix_Zero_79.png', '270_matrix_Zero_80.png',\n",
       "       '270_matrix_Zero_82.png', '270_matrix_Zero_84.png',\n",
       "       '270_matrix_Zero_85.png', '270_matrix_Zero_86.png',\n",
       "       '270_matrix_Zero_88.png', '270_matrix_Zero_89.png',\n",
       "       '270_matrix_Zero_9.png', '270_matrix_Zero_90.png',\n",
       "       '270_matrix_Zero_91.png', '270_matrix_Zero_94.png',\n",
       "       '270_matrix_Zero_96.png', '270_matrix_Zero_97.png',\n",
       "       '270_matrix_Zero_98.png', '270_matrix_Zero_99.png',\n",
       "       '90_matrix_Zero_1.png', '90_matrix_Zero_100.png',\n",
       "       '90_matrix_Zero_101.png', '90_matrix_Zero_102.png',\n",
       "       '90_matrix_Zero_103.png', '90_matrix_Zero_104.png',\n",
       "       '90_matrix_Zero_105.png', '90_matrix_Zero_106.png',\n",
       "       '90_matrix_Zero_107.png', '90_matrix_Zero_108.png',\n",
       "       '90_matrix_Zero_109.png', '90_matrix_Zero_112.png',\n",
       "       '90_matrix_Zero_113.png', '90_matrix_Zero_115.png',\n",
       "       '90_matrix_Zero_118.png', '90_matrix_Zero_119.png',\n",
       "       '90_matrix_Zero_120.png', '90_matrix_Zero_121.png',\n",
       "       '90_matrix_Zero_122.png', '90_matrix_Zero_123.png',\n",
       "       '90_matrix_Zero_124.png', '90_matrix_Zero_125.png',\n",
       "       '90_matrix_Zero_126.png', '90_matrix_Zero_13.png',\n",
       "       '90_matrix_Zero_130.png', '90_matrix_Zero_133.png',\n",
       "       '90_matrix_Zero_134.png', '90_matrix_Zero_135.png',\n",
       "       '90_matrix_Zero_14.png', '90_matrix_Zero_15.png',\n",
       "       '90_matrix_Zero_16.png', '90_matrix_Zero_17.png',\n",
       "       '90_matrix_Zero_18.png', '90_matrix_Zero_2.png',\n",
       "       '90_matrix_Zero_20.png', '90_matrix_Zero_21.png',\n",
       "       '90_matrix_Zero_22.png', '90_matrix_Zero_23.png',\n",
       "       '90_matrix_Zero_24.png', '90_matrix_Zero_25.png',\n",
       "       '90_matrix_Zero_26.png', '90_matrix_Zero_27.png',\n",
       "       '90_matrix_Zero_3.png', '90_matrix_Zero_30.png',\n",
       "       '90_matrix_Zero_31.png', '90_matrix_Zero_32.png',\n",
       "       '90_matrix_Zero_33.png', '90_matrix_Zero_35.png',\n",
       "       '90_matrix_Zero_37.png', '90_matrix_Zero_38.png',\n",
       "       '90_matrix_Zero_39.png', '90_matrix_Zero_4.png',\n",
       "       '90_matrix_Zero_41.png', '90_matrix_Zero_42.png',\n",
       "       '90_matrix_Zero_43.png', '90_matrix_Zero_45.png',\n",
       "       '90_matrix_Zero_46.png', '90_matrix_Zero_47.png',\n",
       "       '90_matrix_Zero_48.png', '90_matrix_Zero_50.png',\n",
       "       '90_matrix_Zero_51.png', '90_matrix_Zero_52.png',\n",
       "       '90_matrix_Zero_53.png', '90_matrix_Zero_54.png',\n",
       "       '90_matrix_Zero_55.png', '90_matrix_Zero_56.png',\n",
       "       '90_matrix_Zero_57.png', '90_matrix_Zero_58.png',\n",
       "       '90_matrix_Zero_6.png', '90_matrix_Zero_61.png',\n",
       "       '90_matrix_Zero_65.png', '90_matrix_Zero_66.png',\n",
       "       '90_matrix_Zero_67.png', '90_matrix_Zero_68.png',\n",
       "       '90_matrix_Zero_69.png', '90_matrix_Zero_7.png',\n",
       "       '90_matrix_Zero_71.png', '90_matrix_Zero_74.png',\n",
       "       '90_matrix_Zero_77.png', '90_matrix_Zero_78.png',\n",
       "       '90_matrix_Zero_79.png', '90_matrix_Zero_80.png',\n",
       "       '90_matrix_Zero_82.png', '90_matrix_Zero_84.png',\n",
       "       '90_matrix_Zero_85.png', '90_matrix_Zero_86.png',\n",
       "       '90_matrix_Zero_88.png', '90_matrix_Zero_89.png',\n",
       "       '90_matrix_Zero_9.png', '90_matrix_Zero_90.png',\n",
       "       '90_matrix_Zero_91.png', '90_matrix_Zero_94.png',\n",
       "       '90_matrix_Zero_96.png', '90_matrix_Zero_97.png',\n",
       "       '90_matrix_Zero_98.png', '90_matrix_Zero_99.png',\n",
       "       'matrix_Zero_1.png', 'matrix_Zero_100.png', 'matrix_Zero_101.png',\n",
       "       'matrix_Zero_102.png', 'matrix_Zero_103.png',\n",
       "       'matrix_Zero_104.png', 'matrix_Zero_105.png',\n",
       "       'matrix_Zero_106.png', 'matrix_Zero_107.png',\n",
       "       'matrix_Zero_108.png', 'matrix_Zero_109.png',\n",
       "       'matrix_Zero_112.png', 'matrix_Zero_113.png',\n",
       "       'matrix_Zero_115.png', 'matrix_Zero_118.png',\n",
       "       'matrix_Zero_119.png', 'matrix_Zero_120.png',\n",
       "       'matrix_Zero_121.png', 'matrix_Zero_122.png',\n",
       "       'matrix_Zero_123.png', 'matrix_Zero_124.png',\n",
       "       'matrix_Zero_125.png', 'matrix_Zero_126.png', 'matrix_Zero_13.png',\n",
       "       'matrix_Zero_130.png', 'matrix_Zero_133.png',\n",
       "       'matrix_Zero_134.png', 'matrix_Zero_135.png', 'matrix_Zero_14.png',\n",
       "       'matrix_Zero_15.png', 'matrix_Zero_16.png', 'matrix_Zero_17.png',\n",
       "       'matrix_Zero_18.png', 'matrix_Zero_2.png', 'matrix_Zero_20.png',\n",
       "       'matrix_Zero_21.png', 'matrix_Zero_22.png', 'matrix_Zero_23.png',\n",
       "       'matrix_Zero_24.png', 'matrix_Zero_25.png', 'matrix_Zero_26.png',\n",
       "       'matrix_Zero_27.png', 'matrix_Zero_3.png', 'matrix_Zero_30.png',\n",
       "       'matrix_Zero_31.png', 'matrix_Zero_32.png', 'matrix_Zero_33.png',\n",
       "       'matrix_Zero_35.png', 'matrix_Zero_37.png', 'matrix_Zero_38.png',\n",
       "       'matrix_Zero_39.png', 'matrix_Zero_4.png', 'matrix_Zero_41.png',\n",
       "       'matrix_Zero_42.png', 'matrix_Zero_43.png', 'matrix_Zero_45.png',\n",
       "       'matrix_Zero_46.png', 'matrix_Zero_47.png', 'matrix_Zero_48.png',\n",
       "       'matrix_Zero_50.png', 'matrix_Zero_51.png', 'matrix_Zero_52.png',\n",
       "       'matrix_Zero_53.png', 'matrix_Zero_54.png', 'matrix_Zero_55.png',\n",
       "       'matrix_Zero_56.png', 'matrix_Zero_57.png', 'matrix_Zero_58.png',\n",
       "       'matrix_Zero_6.png', 'matrix_Zero_61.png', 'matrix_Zero_65.png',\n",
       "       'matrix_Zero_66.png', 'matrix_Zero_67.png', 'matrix_Zero_68.png',\n",
       "       'matrix_Zero_69.png', 'matrix_Zero_7.png', 'matrix_Zero_71.png',\n",
       "       'matrix_Zero_74.png', 'matrix_Zero_77.png', 'matrix_Zero_78.png',\n",
       "       'matrix_Zero_79.png', 'matrix_Zero_80.png', 'matrix_Zero_82.png',\n",
       "       'matrix_Zero_84.png', 'matrix_Zero_85.png', 'matrix_Zero_86.png',\n",
       "       'matrix_Zero_88.png', 'matrix_Zero_89.png', 'matrix_Zero_9.png',\n",
       "       'matrix_Zero_90.png', 'matrix_Zero_91.png', 'matrix_Zero_94.png',\n",
       "       'matrix_Zero_96.png', 'matrix_Zero_97.png', 'matrix_Zero_98.png',\n",
       "       'matrix_Zero_99.png'], dtype='<U23')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ラベル： 180_matrix_One_0.png\n",
      "ラベル： 180_matrix_One_10.png\n",
      "ラベル： 180_matrix_One_12.png\n",
      "ラベル： 180_matrix_One_13.png\n",
      "ラベル： 180_matrix_One_15.png\n",
      "ラベル： 180_matrix_One_19.png\n",
      "ラベル： 180_matrix_One_2.png\n",
      "ラベル： 180_matrix_One_20.png\n",
      "ラベル： 180_matrix_One_21.png\n",
      "ラベル： 180_matrix_One_22.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "for i in range(0, 10):\n",
    "    print(\"ラベル：\", n[i])\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.axis('on')\n",
    "    #plt.title(label = 'Zero' if y[i] == 0 else 'One')\n",
    "    img_array = cv2.cvtColor(X[i], cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=1, padding=\"same\"))\n",
    "#model.add(Conv2D(32, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), strides=1, padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, input_dim=32, kernel_regularizer=regularizers.l2(0.01))) #regularizer\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer='rmsprop', #rmsprop is better loss data\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59, 186, 117, 255],\n",
       "         [ 33, 166, 133, 255],\n",
       "         [ 46, 107, 142, 255],\n",
       "         [162, 218,  55, 255],\n",
       "         [ 71, 192, 110, 255],\n",
       "         [ 68, 190, 112, 255]],\n",
       "\n",
       "        [[ 98, 202,  95, 255],\n",
       "         [ 40, 122, 142, 255],\n",
       "         [ 46, 107, 142, 255],\n",
       "         [ 34, 167, 132, 255],\n",
       "         [ 81, 196, 104, 255],\n",
       "         [ 68, 190, 112, 255]],\n",
       "\n",
       "        [[ 63,  69, 135, 255],\n",
       "         [ 55,  89, 140, 255],\n",
       "         [ 36, 134, 141, 255],\n",
       "         [ 70,  45, 124, 255],\n",
       "         [ 50,  99, 141, 255],\n",
       "         [ 43, 115, 142, 255]],\n",
       "\n",
       "        [[253, 231,  36, 255],\n",
       "         [ 34, 138, 141, 255],\n",
       "         [ 42, 117, 142, 255],\n",
       "         [ 59, 186, 117, 255],\n",
       "         [ 47, 105, 141, 255],\n",
       "         [175, 220,  46, 255]],\n",
       "\n",
       "        [[ 68,   1,  84, 255],\n",
       "         [ 68,   1,  84, 255],\n",
       "         [ 41, 120, 142, 255],\n",
       "         [ 51,  97, 141, 255],\n",
       "         [ 68,   1,  84, 255],\n",
       "         [ 68,   1,  84, 255]],\n",
       "\n",
       "        [[ 60,  78, 138, 255],\n",
       "         [253, 231,  36, 255],\n",
       "         [ 40, 122, 142, 255],\n",
       "         [ 41, 120, 142, 255],\n",
       "         [ 71,  42, 121, 255],\n",
       "         [ 51,  97, 141, 255]]],\n",
       "\n",
       "\n",
       "       [[[ 65,  65, 134, 255],\n",
       "         [ 57,  85, 139, 255],\n",
       "         [ 37, 131, 141, 255],\n",
       "         [ 71,  39, 119, 255],\n",
       "         [ 51,  96, 141, 255],\n",
       "         [ 44, 112, 142, 255]],\n",
       "\n",
       "        [[ 56, 185, 118, 255],\n",
       "         [ 31, 163, 134, 255],\n",
       "         [ 48, 104, 141, 255],\n",
       "         [159, 217,  56, 255],\n",
       "         [ 69, 191, 111, 255],\n",
       "         [ 64, 189, 114, 255]],\n",
       "\n",
       "        [[ 65,  65, 134, 255],\n",
       "         [ 57,  85, 139, 255],\n",
       "         [ 37, 131, 141, 255],\n",
       "         [ 71,  39, 119, 255],\n",
       "         [ 51,  96, 141, 255],\n",
       "         [ 44, 112, 142, 255]],\n",
       "\n",
       "        [[ 44, 112, 142, 255],\n",
       "         [ 61,  74, 137, 255],\n",
       "         [ 48, 104, 141, 255],\n",
       "         [ 54,  91, 140, 255],\n",
       "         [ 70,  45, 124, 255],\n",
       "         [ 53,  93, 140, 255]],\n",
       "\n",
       "        [[ 68,  55, 129, 255],\n",
       "         [253, 231,  36, 255],\n",
       "         [ 68,   1,  84, 255],\n",
       "         [ 72,  33, 114, 255],\n",
       "         [ 46, 109, 142, 255],\n",
       "         [ 46, 109, 142, 255]],\n",
       "\n",
       "        [[ 56, 185, 118, 255],\n",
       "         [ 31, 163, 134, 255],\n",
       "         [ 48, 104, 141, 255],\n",
       "         [159, 217,  56, 255],\n",
       "         [ 69, 191, 111, 255],\n",
       "         [ 64, 189, 114, 255]]],\n",
       "\n",
       "\n",
       "       [[[ 68,  55, 129, 255],\n",
       "         [253, 231,  36, 255],\n",
       "         [ 68,   1,  84, 255],\n",
       "         [ 72,  33, 114, 255],\n",
       "         [ 46, 109, 142, 255],\n",
       "         [ 46, 109, 142, 255]],\n",
       "\n",
       "        [[173, 220,  48, 255],\n",
       "         [ 31, 163, 134, 255],\n",
       "         [ 42, 117, 142, 255],\n",
       "         [159, 217,  56, 255],\n",
       "         [ 37, 131, 141, 255],\n",
       "         [253, 231,  36, 255]],\n",
       "\n",
       "        [[173, 220,  48, 255],\n",
       "         [ 31, 163, 134, 255],\n",
       "         [ 42, 117, 142, 255],\n",
       "         [159, 217,  56, 255],\n",
       "         [ 37, 131, 141, 255],\n",
       "         [253, 231,  36, 255]],\n",
       "\n",
       "        [[253, 231,  36, 255],\n",
       "         [ 35, 137, 141, 255],\n",
       "         [ 44, 114, 142, 255],\n",
       "         [ 56, 185, 118, 255],\n",
       "         [ 49, 101, 141, 255],\n",
       "         [173, 220,  48, 255]],\n",
       "\n",
       "        [[ 36, 170, 130, 255],\n",
       "         [ 57,  85, 139, 255],\n",
       "         [ 49, 101, 141, 255],\n",
       "         [ 44, 114, 142, 255],\n",
       "         [ 58,  83, 139, 255],\n",
       "         [ 73, 193, 109, 255]],\n",
       "\n",
       "        [[ 56, 185, 118, 255],\n",
       "         [ 31, 163, 134, 255],\n",
       "         [ 48, 104, 141, 255],\n",
       "         [159, 217,  56, 255],\n",
       "         [ 69, 191, 111, 255],\n",
       "         [ 64, 189, 114, 255]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 30, 158, 136, 255],\n",
       "         [ 71, 192, 110, 255],\n",
       "         [ 68,   1,  84, 255],\n",
       "         [253, 231,  36, 255],\n",
       "         [116, 208,  84, 255],\n",
       "         [ 53,  92, 140, 255]],\n",
       "\n",
       "        [[ 77, 194, 107, 255],\n",
       "         [ 56,  87, 140, 255],\n",
       "         [ 42, 117, 142, 255],\n",
       "         [ 47, 105, 141, 255],\n",
       "         [ 55,  89, 140, 255],\n",
       "         [ 38, 172, 129, 255]],\n",
       "\n",
       "        [[ 43, 177, 125, 255],\n",
       "         [ 68,   1,  84, 255],\n",
       "         [ 30, 151, 138, 255],\n",
       "         [ 33, 141, 140, 255],\n",
       "         [ 68,   1,  84, 255],\n",
       "         [ 30, 158, 136, 255]],\n",
       "\n",
       "        [[ 36, 132, 141, 255],\n",
       "         [ 30, 153, 138, 255],\n",
       "         [ 68,   3,  87, 255],\n",
       "         [189, 222,  38, 255],\n",
       "         [ 50, 181, 122, 255],\n",
       "         [ 46, 107, 142, 255]],\n",
       "\n",
       "        [[253, 231,  36, 255],\n",
       "         [ 36, 134, 141, 255],\n",
       "         [162, 218,  55, 255],\n",
       "         [ 41, 120, 142, 255],\n",
       "         [ 33, 166, 133, 255],\n",
       "         [175, 220,  46, 255]],\n",
       "\n",
       "        [[ 44, 112, 142, 255],\n",
       "         [ 38, 129, 142, 255],\n",
       "         [ 60,  78, 138, 255],\n",
       "         [ 46, 107, 142, 255],\n",
       "         [116, 208,  84, 255],\n",
       "         [ 53,  92, 140, 255]]],\n",
       "\n",
       "\n",
       "       [[[ 30, 158, 136, 255],\n",
       "         [ 71, 192, 110, 255],\n",
       "         [ 68,   1,  84, 255],\n",
       "         [253, 231,  36, 255],\n",
       "         [116, 208,  84, 255],\n",
       "         [ 53,  92, 140, 255]],\n",
       "\n",
       "        [[175, 220,  46, 255],\n",
       "         [ 47, 105, 141, 255],\n",
       "         [ 59, 186, 117, 255],\n",
       "         [ 42, 117, 142, 255],\n",
       "         [ 34, 138, 141, 255],\n",
       "         [253, 231,  36, 255]],\n",
       "\n",
       "        [[ 51,  97, 141, 255],\n",
       "         [ 71,  42, 121, 255],\n",
       "         [ 41, 120, 142, 255],\n",
       "         [ 40, 122, 142, 255],\n",
       "         [253, 231,  36, 255],\n",
       "         [ 60,  78, 138, 255]],\n",
       "\n",
       "        [[ 68, 190, 112, 255],\n",
       "         [ 71, 192, 110, 255],\n",
       "         [162, 218,  55, 255],\n",
       "         [ 46, 107, 142, 255],\n",
       "         [ 33, 166, 133, 255],\n",
       "         [ 59, 186, 117, 255]],\n",
       "\n",
       "        [[ 68, 190, 112, 255],\n",
       "         [ 71, 192, 110, 255],\n",
       "         [162, 218,  55, 255],\n",
       "         [ 46, 107, 142, 255],\n",
       "         [ 33, 166, 133, 255],\n",
       "         [ 59, 186, 117, 255]],\n",
       "\n",
       "        [[ 44, 112, 142, 255],\n",
       "         [ 44, 112, 142, 255],\n",
       "         [ 71,  39, 119, 255],\n",
       "         [ 69,   8,  91, 255],\n",
       "         [253, 231,  36, 255],\n",
       "         [ 66,  61, 132, 255]]],\n",
       "\n",
       "\n",
       "       [[[ 30, 158, 136, 255],\n",
       "         [ 71, 192, 110, 255],\n",
       "         [ 68,   1,  84, 255],\n",
       "         [253, 231,  36, 255],\n",
       "         [116, 208,  84, 255],\n",
       "         [ 53,  92, 140, 255]],\n",
       "\n",
       "        [[175, 220,  46, 255],\n",
       "         [ 47, 105, 141, 255],\n",
       "         [ 59, 186, 117, 255],\n",
       "         [ 42, 117, 142, 255],\n",
       "         [ 34, 138, 141, 255],\n",
       "         [253, 231,  36, 255]],\n",
       "\n",
       "        [[ 43, 115, 142, 255],\n",
       "         [ 50,  99, 141, 255],\n",
       "         [ 70,  45, 124, 255],\n",
       "         [ 36, 134, 141, 255],\n",
       "         [ 55,  89, 140, 255],\n",
       "         [ 63,  69, 135, 255]],\n",
       "\n",
       "        [[ 71, 192, 110, 255],\n",
       "         [ 30, 158, 136, 255],\n",
       "         [ 46, 107, 142, 255],\n",
       "         [ 36, 170, 130, 255],\n",
       "         [ 34, 138, 141, 255],\n",
       "         [ 38, 129, 142, 255]],\n",
       "\n",
       "        [[175, 220,  46, 255],\n",
       "         [ 47, 105, 141, 255],\n",
       "         [ 59, 186, 117, 255],\n",
       "         [ 42, 117, 142, 255],\n",
       "         [ 34, 138, 141, 255],\n",
       "         [253, 231,  36, 255]],\n",
       "\n",
       "        [[ 77, 194, 107, 255],\n",
       "         [ 56,  87, 140, 255],\n",
       "         [ 42, 117, 142, 255],\n",
       "         [ 47, 105, 141, 255],\n",
       "         [ 55,  89, 140, 255],\n",
       "         [ 38, 172, 129, 255]]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3d0c031b77b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mXa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'XX' is not defined"
     ]
    }
   ],
   "source": [
    "Xa=X[:,:,:,:3]\n",
    "print(XX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59, 186, 117],\n",
       "         [ 33, 166, 133],\n",
       "         [ 46, 107, 142],\n",
       "         [162, 218,  55],\n",
       "         [ 71, 192, 110],\n",
       "         [ 68, 190, 112]],\n",
       "\n",
       "        [[ 98, 202,  95],\n",
       "         [ 40, 122, 142],\n",
       "         [ 46, 107, 142],\n",
       "         [ 34, 167, 132],\n",
       "         [ 81, 196, 104],\n",
       "         [ 68, 190, 112]],\n",
       "\n",
       "        [[ 63,  69, 135],\n",
       "         [ 55,  89, 140],\n",
       "         [ 36, 134, 141],\n",
       "         [ 70,  45, 124],\n",
       "         [ 50,  99, 141],\n",
       "         [ 43, 115, 142]],\n",
       "\n",
       "        [[253, 231,  36],\n",
       "         [ 34, 138, 141],\n",
       "         [ 42, 117, 142],\n",
       "         [ 59, 186, 117],\n",
       "         [ 47, 105, 141],\n",
       "         [175, 220,  46]],\n",
       "\n",
       "        [[ 68,   1,  84],\n",
       "         [ 68,   1,  84],\n",
       "         [ 41, 120, 142],\n",
       "         [ 51,  97, 141],\n",
       "         [ 68,   1,  84],\n",
       "         [ 68,   1,  84]],\n",
       "\n",
       "        [[ 60,  78, 138],\n",
       "         [253, 231,  36],\n",
       "         [ 40, 122, 142],\n",
       "         [ 41, 120, 142],\n",
       "         [ 71,  42, 121],\n",
       "         [ 51,  97, 141]]],\n",
       "\n",
       "\n",
       "       [[[ 65,  65, 134],\n",
       "         [ 57,  85, 139],\n",
       "         [ 37, 131, 141],\n",
       "         [ 71,  39, 119],\n",
       "         [ 51,  96, 141],\n",
       "         [ 44, 112, 142]],\n",
       "\n",
       "        [[ 56, 185, 118],\n",
       "         [ 31, 163, 134],\n",
       "         [ 48, 104, 141],\n",
       "         [159, 217,  56],\n",
       "         [ 69, 191, 111],\n",
       "         [ 64, 189, 114]],\n",
       "\n",
       "        [[ 65,  65, 134],\n",
       "         [ 57,  85, 139],\n",
       "         [ 37, 131, 141],\n",
       "         [ 71,  39, 119],\n",
       "         [ 51,  96, 141],\n",
       "         [ 44, 112, 142]],\n",
       "\n",
       "        [[ 44, 112, 142],\n",
       "         [ 61,  74, 137],\n",
       "         [ 48, 104, 141],\n",
       "         [ 54,  91, 140],\n",
       "         [ 70,  45, 124],\n",
       "         [ 53,  93, 140]],\n",
       "\n",
       "        [[ 68,  55, 129],\n",
       "         [253, 231,  36],\n",
       "         [ 68,   1,  84],\n",
       "         [ 72,  33, 114],\n",
       "         [ 46, 109, 142],\n",
       "         [ 46, 109, 142]],\n",
       "\n",
       "        [[ 56, 185, 118],\n",
       "         [ 31, 163, 134],\n",
       "         [ 48, 104, 141],\n",
       "         [159, 217,  56],\n",
       "         [ 69, 191, 111],\n",
       "         [ 64, 189, 114]]],\n",
       "\n",
       "\n",
       "       [[[ 68,  55, 129],\n",
       "         [253, 231,  36],\n",
       "         [ 68,   1,  84],\n",
       "         [ 72,  33, 114],\n",
       "         [ 46, 109, 142],\n",
       "         [ 46, 109, 142]],\n",
       "\n",
       "        [[173, 220,  48],\n",
       "         [ 31, 163, 134],\n",
       "         [ 42, 117, 142],\n",
       "         [159, 217,  56],\n",
       "         [ 37, 131, 141],\n",
       "         [253, 231,  36]],\n",
       "\n",
       "        [[173, 220,  48],\n",
       "         [ 31, 163, 134],\n",
       "         [ 42, 117, 142],\n",
       "         [159, 217,  56],\n",
       "         [ 37, 131, 141],\n",
       "         [253, 231,  36]],\n",
       "\n",
       "        [[253, 231,  36],\n",
       "         [ 35, 137, 141],\n",
       "         [ 44, 114, 142],\n",
       "         [ 56, 185, 118],\n",
       "         [ 49, 101, 141],\n",
       "         [173, 220,  48]],\n",
       "\n",
       "        [[ 36, 170, 130],\n",
       "         [ 57,  85, 139],\n",
       "         [ 49, 101, 141],\n",
       "         [ 44, 114, 142],\n",
       "         [ 58,  83, 139],\n",
       "         [ 73, 193, 109]],\n",
       "\n",
       "        [[ 56, 185, 118],\n",
       "         [ 31, 163, 134],\n",
       "         [ 48, 104, 141],\n",
       "         [159, 217,  56],\n",
       "         [ 69, 191, 111],\n",
       "         [ 64, 189, 114]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 30, 158, 136],\n",
       "         [ 71, 192, 110],\n",
       "         [ 68,   1,  84],\n",
       "         [253, 231,  36],\n",
       "         [116, 208,  84],\n",
       "         [ 53,  92, 140]],\n",
       "\n",
       "        [[ 77, 194, 107],\n",
       "         [ 56,  87, 140],\n",
       "         [ 42, 117, 142],\n",
       "         [ 47, 105, 141],\n",
       "         [ 55,  89, 140],\n",
       "         [ 38, 172, 129]],\n",
       "\n",
       "        [[ 43, 177, 125],\n",
       "         [ 68,   1,  84],\n",
       "         [ 30, 151, 138],\n",
       "         [ 33, 141, 140],\n",
       "         [ 68,   1,  84],\n",
       "         [ 30, 158, 136]],\n",
       "\n",
       "        [[ 36, 132, 141],\n",
       "         [ 30, 153, 138],\n",
       "         [ 68,   3,  87],\n",
       "         [189, 222,  38],\n",
       "         [ 50, 181, 122],\n",
       "         [ 46, 107, 142]],\n",
       "\n",
       "        [[253, 231,  36],\n",
       "         [ 36, 134, 141],\n",
       "         [162, 218,  55],\n",
       "         [ 41, 120, 142],\n",
       "         [ 33, 166, 133],\n",
       "         [175, 220,  46]],\n",
       "\n",
       "        [[ 44, 112, 142],\n",
       "         [ 38, 129, 142],\n",
       "         [ 60,  78, 138],\n",
       "         [ 46, 107, 142],\n",
       "         [116, 208,  84],\n",
       "         [ 53,  92, 140]]],\n",
       "\n",
       "\n",
       "       [[[ 30, 158, 136],\n",
       "         [ 71, 192, 110],\n",
       "         [ 68,   1,  84],\n",
       "         [253, 231,  36],\n",
       "         [116, 208,  84],\n",
       "         [ 53,  92, 140]],\n",
       "\n",
       "        [[175, 220,  46],\n",
       "         [ 47, 105, 141],\n",
       "         [ 59, 186, 117],\n",
       "         [ 42, 117, 142],\n",
       "         [ 34, 138, 141],\n",
       "         [253, 231,  36]],\n",
       "\n",
       "        [[ 51,  97, 141],\n",
       "         [ 71,  42, 121],\n",
       "         [ 41, 120, 142],\n",
       "         [ 40, 122, 142],\n",
       "         [253, 231,  36],\n",
       "         [ 60,  78, 138]],\n",
       "\n",
       "        [[ 68, 190, 112],\n",
       "         [ 71, 192, 110],\n",
       "         [162, 218,  55],\n",
       "         [ 46, 107, 142],\n",
       "         [ 33, 166, 133],\n",
       "         [ 59, 186, 117]],\n",
       "\n",
       "        [[ 68, 190, 112],\n",
       "         [ 71, 192, 110],\n",
       "         [162, 218,  55],\n",
       "         [ 46, 107, 142],\n",
       "         [ 33, 166, 133],\n",
       "         [ 59, 186, 117]],\n",
       "\n",
       "        [[ 44, 112, 142],\n",
       "         [ 44, 112, 142],\n",
       "         [ 71,  39, 119],\n",
       "         [ 69,   8,  91],\n",
       "         [253, 231,  36],\n",
       "         [ 66,  61, 132]]],\n",
       "\n",
       "\n",
       "       [[[ 30, 158, 136],\n",
       "         [ 71, 192, 110],\n",
       "         [ 68,   1,  84],\n",
       "         [253, 231,  36],\n",
       "         [116, 208,  84],\n",
       "         [ 53,  92, 140]],\n",
       "\n",
       "        [[175, 220,  46],\n",
       "         [ 47, 105, 141],\n",
       "         [ 59, 186, 117],\n",
       "         [ 42, 117, 142],\n",
       "         [ 34, 138, 141],\n",
       "         [253, 231,  36]],\n",
       "\n",
       "        [[ 43, 115, 142],\n",
       "         [ 50,  99, 141],\n",
       "         [ 70,  45, 124],\n",
       "         [ 36, 134, 141],\n",
       "         [ 55,  89, 140],\n",
       "         [ 63,  69, 135]],\n",
       "\n",
       "        [[ 71, 192, 110],\n",
       "         [ 30, 158, 136],\n",
       "         [ 46, 107, 142],\n",
       "         [ 36, 170, 130],\n",
       "         [ 34, 138, 141],\n",
       "         [ 38, 129, 142]],\n",
       "\n",
       "        [[175, 220,  46],\n",
       "         [ 47, 105, 141],\n",
       "         [ 59, 186, 117],\n",
       "         [ 42, 117, 142],\n",
       "         [ 34, 138, 141],\n",
       "         [253, 231,  36]],\n",
       "\n",
       "        [[ 77, 194, 107],\n",
       "         [ 56,  87, 140],\n",
       "         [ 42, 117, 142],\n",
       "         [ 47, 105, 141],\n",
       "         [ 55,  89, 140],\n",
       "         [ 38, 172, 129]]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb = Xa.astype(\"float32\")\n",
    "Xb = Xa / 255  # [0, 1] にする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.23137255, 0.72941176, 0.45882353],\n",
       "         [0.12941176, 0.65098039, 0.52156863],\n",
       "         [0.18039216, 0.41960784, 0.55686275],\n",
       "         [0.63529412, 0.85490196, 0.21568627],\n",
       "         [0.27843137, 0.75294118, 0.43137255],\n",
       "         [0.26666667, 0.74509804, 0.43921569]],\n",
       "\n",
       "        [[0.38431373, 0.79215686, 0.37254902],\n",
       "         [0.15686275, 0.47843137, 0.55686275],\n",
       "         [0.18039216, 0.41960784, 0.55686275],\n",
       "         [0.13333333, 0.65490196, 0.51764706],\n",
       "         [0.31764706, 0.76862745, 0.40784314],\n",
       "         [0.26666667, 0.74509804, 0.43921569]],\n",
       "\n",
       "        [[0.24705882, 0.27058824, 0.52941176],\n",
       "         [0.21568627, 0.34901961, 0.54901961],\n",
       "         [0.14117647, 0.5254902 , 0.55294118],\n",
       "         [0.2745098 , 0.17647059, 0.48627451],\n",
       "         [0.19607843, 0.38823529, 0.55294118],\n",
       "         [0.16862745, 0.45098039, 0.55686275]],\n",
       "\n",
       "        [[0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.13333333, 0.54117647, 0.55294118],\n",
       "         [0.16470588, 0.45882353, 0.55686275],\n",
       "         [0.23137255, 0.72941176, 0.45882353],\n",
       "         [0.18431373, 0.41176471, 0.55294118],\n",
       "         [0.68627451, 0.8627451 , 0.18039216]],\n",
       "\n",
       "        [[0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.16078431, 0.47058824, 0.55686275],\n",
       "         [0.2       , 0.38039216, 0.55294118],\n",
       "         [0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.26666667, 0.00392157, 0.32941176]],\n",
       "\n",
       "        [[0.23529412, 0.30588235, 0.54117647],\n",
       "         [0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.15686275, 0.47843137, 0.55686275],\n",
       "         [0.16078431, 0.47058824, 0.55686275],\n",
       "         [0.27843137, 0.16470588, 0.4745098 ],\n",
       "         [0.2       , 0.38039216, 0.55294118]]],\n",
       "\n",
       "\n",
       "       [[[0.25490196, 0.25490196, 0.5254902 ],\n",
       "         [0.22352941, 0.33333333, 0.54509804],\n",
       "         [0.14509804, 0.51372549, 0.55294118],\n",
       "         [0.27843137, 0.15294118, 0.46666667],\n",
       "         [0.2       , 0.37647059, 0.55294118],\n",
       "         [0.17254902, 0.43921569, 0.55686275]],\n",
       "\n",
       "        [[0.21960784, 0.7254902 , 0.4627451 ],\n",
       "         [0.12156863, 0.63921569, 0.5254902 ],\n",
       "         [0.18823529, 0.40784314, 0.55294118],\n",
       "         [0.62352941, 0.85098039, 0.21960784],\n",
       "         [0.27058824, 0.74901961, 0.43529412],\n",
       "         [0.25098039, 0.74117647, 0.44705882]],\n",
       "\n",
       "        [[0.25490196, 0.25490196, 0.5254902 ],\n",
       "         [0.22352941, 0.33333333, 0.54509804],\n",
       "         [0.14509804, 0.51372549, 0.55294118],\n",
       "         [0.27843137, 0.15294118, 0.46666667],\n",
       "         [0.2       , 0.37647059, 0.55294118],\n",
       "         [0.17254902, 0.43921569, 0.55686275]],\n",
       "\n",
       "        [[0.17254902, 0.43921569, 0.55686275],\n",
       "         [0.23921569, 0.29019608, 0.5372549 ],\n",
       "         [0.18823529, 0.40784314, 0.55294118],\n",
       "         [0.21176471, 0.35686275, 0.54901961],\n",
       "         [0.2745098 , 0.17647059, 0.48627451],\n",
       "         [0.20784314, 0.36470588, 0.54901961]],\n",
       "\n",
       "        [[0.26666667, 0.21568627, 0.50588235],\n",
       "         [0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.28235294, 0.12941176, 0.44705882],\n",
       "         [0.18039216, 0.42745098, 0.55686275],\n",
       "         [0.18039216, 0.42745098, 0.55686275]],\n",
       "\n",
       "        [[0.21960784, 0.7254902 , 0.4627451 ],\n",
       "         [0.12156863, 0.63921569, 0.5254902 ],\n",
       "         [0.18823529, 0.40784314, 0.55294118],\n",
       "         [0.62352941, 0.85098039, 0.21960784],\n",
       "         [0.27058824, 0.74901961, 0.43529412],\n",
       "         [0.25098039, 0.74117647, 0.44705882]]],\n",
       "\n",
       "\n",
       "       [[[0.26666667, 0.21568627, 0.50588235],\n",
       "         [0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.28235294, 0.12941176, 0.44705882],\n",
       "         [0.18039216, 0.42745098, 0.55686275],\n",
       "         [0.18039216, 0.42745098, 0.55686275]],\n",
       "\n",
       "        [[0.67843137, 0.8627451 , 0.18823529],\n",
       "         [0.12156863, 0.63921569, 0.5254902 ],\n",
       "         [0.16470588, 0.45882353, 0.55686275],\n",
       "         [0.62352941, 0.85098039, 0.21960784],\n",
       "         [0.14509804, 0.51372549, 0.55294118],\n",
       "         [0.99215686, 0.90588235, 0.14117647]],\n",
       "\n",
       "        [[0.67843137, 0.8627451 , 0.18823529],\n",
       "         [0.12156863, 0.63921569, 0.5254902 ],\n",
       "         [0.16470588, 0.45882353, 0.55686275],\n",
       "         [0.62352941, 0.85098039, 0.21960784],\n",
       "         [0.14509804, 0.51372549, 0.55294118],\n",
       "         [0.99215686, 0.90588235, 0.14117647]],\n",
       "\n",
       "        [[0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.1372549 , 0.5372549 , 0.55294118],\n",
       "         [0.17254902, 0.44705882, 0.55686275],\n",
       "         [0.21960784, 0.7254902 , 0.4627451 ],\n",
       "         [0.19215686, 0.39607843, 0.55294118],\n",
       "         [0.67843137, 0.8627451 , 0.18823529]],\n",
       "\n",
       "        [[0.14117647, 0.66666667, 0.50980392],\n",
       "         [0.22352941, 0.33333333, 0.54509804],\n",
       "         [0.19215686, 0.39607843, 0.55294118],\n",
       "         [0.17254902, 0.44705882, 0.55686275],\n",
       "         [0.22745098, 0.3254902 , 0.54509804],\n",
       "         [0.28627451, 0.75686275, 0.42745098]],\n",
       "\n",
       "        [[0.21960784, 0.7254902 , 0.4627451 ],\n",
       "         [0.12156863, 0.63921569, 0.5254902 ],\n",
       "         [0.18823529, 0.40784314, 0.55294118],\n",
       "         [0.62352941, 0.85098039, 0.21960784],\n",
       "         [0.27058824, 0.74901961, 0.43529412],\n",
       "         [0.25098039, 0.74117647, 0.44705882]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.11764706, 0.61960784, 0.53333333],\n",
       "         [0.27843137, 0.75294118, 0.43137255],\n",
       "         [0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.45490196, 0.81568627, 0.32941176],\n",
       "         [0.20784314, 0.36078431, 0.54901961]],\n",
       "\n",
       "        [[0.30196078, 0.76078431, 0.41960784],\n",
       "         [0.21960784, 0.34117647, 0.54901961],\n",
       "         [0.16470588, 0.45882353, 0.55686275],\n",
       "         [0.18431373, 0.41176471, 0.55294118],\n",
       "         [0.21568627, 0.34901961, 0.54901961],\n",
       "         [0.14901961, 0.6745098 , 0.50588235]],\n",
       "\n",
       "        [[0.16862745, 0.69411765, 0.49019608],\n",
       "         [0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.11764706, 0.59215686, 0.54117647],\n",
       "         [0.12941176, 0.55294118, 0.54901961],\n",
       "         [0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.11764706, 0.61960784, 0.53333333]],\n",
       "\n",
       "        [[0.14117647, 0.51764706, 0.55294118],\n",
       "         [0.11764706, 0.6       , 0.54117647],\n",
       "         [0.26666667, 0.01176471, 0.34117647],\n",
       "         [0.74117647, 0.87058824, 0.14901961],\n",
       "         [0.19607843, 0.70980392, 0.47843137],\n",
       "         [0.18039216, 0.41960784, 0.55686275]],\n",
       "\n",
       "        [[0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.14117647, 0.5254902 , 0.55294118],\n",
       "         [0.63529412, 0.85490196, 0.21568627],\n",
       "         [0.16078431, 0.47058824, 0.55686275],\n",
       "         [0.12941176, 0.65098039, 0.52156863],\n",
       "         [0.68627451, 0.8627451 , 0.18039216]],\n",
       "\n",
       "        [[0.17254902, 0.43921569, 0.55686275],\n",
       "         [0.14901961, 0.50588235, 0.55686275],\n",
       "         [0.23529412, 0.30588235, 0.54117647],\n",
       "         [0.18039216, 0.41960784, 0.55686275],\n",
       "         [0.45490196, 0.81568627, 0.32941176],\n",
       "         [0.20784314, 0.36078431, 0.54901961]]],\n",
       "\n",
       "\n",
       "       [[[0.11764706, 0.61960784, 0.53333333],\n",
       "         [0.27843137, 0.75294118, 0.43137255],\n",
       "         [0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.45490196, 0.81568627, 0.32941176],\n",
       "         [0.20784314, 0.36078431, 0.54901961]],\n",
       "\n",
       "        [[0.68627451, 0.8627451 , 0.18039216],\n",
       "         [0.18431373, 0.41176471, 0.55294118],\n",
       "         [0.23137255, 0.72941176, 0.45882353],\n",
       "         [0.16470588, 0.45882353, 0.55686275],\n",
       "         [0.13333333, 0.54117647, 0.55294118],\n",
       "         [0.99215686, 0.90588235, 0.14117647]],\n",
       "\n",
       "        [[0.2       , 0.38039216, 0.55294118],\n",
       "         [0.27843137, 0.16470588, 0.4745098 ],\n",
       "         [0.16078431, 0.47058824, 0.55686275],\n",
       "         [0.15686275, 0.47843137, 0.55686275],\n",
       "         [0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.23529412, 0.30588235, 0.54117647]],\n",
       "\n",
       "        [[0.26666667, 0.74509804, 0.43921569],\n",
       "         [0.27843137, 0.75294118, 0.43137255],\n",
       "         [0.63529412, 0.85490196, 0.21568627],\n",
       "         [0.18039216, 0.41960784, 0.55686275],\n",
       "         [0.12941176, 0.65098039, 0.52156863],\n",
       "         [0.23137255, 0.72941176, 0.45882353]],\n",
       "\n",
       "        [[0.26666667, 0.74509804, 0.43921569],\n",
       "         [0.27843137, 0.75294118, 0.43137255],\n",
       "         [0.63529412, 0.85490196, 0.21568627],\n",
       "         [0.18039216, 0.41960784, 0.55686275],\n",
       "         [0.12941176, 0.65098039, 0.52156863],\n",
       "         [0.23137255, 0.72941176, 0.45882353]],\n",
       "\n",
       "        [[0.17254902, 0.43921569, 0.55686275],\n",
       "         [0.17254902, 0.43921569, 0.55686275],\n",
       "         [0.27843137, 0.15294118, 0.46666667],\n",
       "         [0.27058824, 0.03137255, 0.35686275],\n",
       "         [0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.25882353, 0.23921569, 0.51764706]]],\n",
       "\n",
       "\n",
       "       [[[0.11764706, 0.61960784, 0.53333333],\n",
       "         [0.27843137, 0.75294118, 0.43137255],\n",
       "         [0.26666667, 0.00392157, 0.32941176],\n",
       "         [0.99215686, 0.90588235, 0.14117647],\n",
       "         [0.45490196, 0.81568627, 0.32941176],\n",
       "         [0.20784314, 0.36078431, 0.54901961]],\n",
       "\n",
       "        [[0.68627451, 0.8627451 , 0.18039216],\n",
       "         [0.18431373, 0.41176471, 0.55294118],\n",
       "         [0.23137255, 0.72941176, 0.45882353],\n",
       "         [0.16470588, 0.45882353, 0.55686275],\n",
       "         [0.13333333, 0.54117647, 0.55294118],\n",
       "         [0.99215686, 0.90588235, 0.14117647]],\n",
       "\n",
       "        [[0.16862745, 0.45098039, 0.55686275],\n",
       "         [0.19607843, 0.38823529, 0.55294118],\n",
       "         [0.2745098 , 0.17647059, 0.48627451],\n",
       "         [0.14117647, 0.5254902 , 0.55294118],\n",
       "         [0.21568627, 0.34901961, 0.54901961],\n",
       "         [0.24705882, 0.27058824, 0.52941176]],\n",
       "\n",
       "        [[0.27843137, 0.75294118, 0.43137255],\n",
       "         [0.11764706, 0.61960784, 0.53333333],\n",
       "         [0.18039216, 0.41960784, 0.55686275],\n",
       "         [0.14117647, 0.66666667, 0.50980392],\n",
       "         [0.13333333, 0.54117647, 0.55294118],\n",
       "         [0.14901961, 0.50588235, 0.55686275]],\n",
       "\n",
       "        [[0.68627451, 0.8627451 , 0.18039216],\n",
       "         [0.18431373, 0.41176471, 0.55294118],\n",
       "         [0.23137255, 0.72941176, 0.45882353],\n",
       "         [0.16470588, 0.45882353, 0.55686275],\n",
       "         [0.13333333, 0.54117647, 0.55294118],\n",
       "         [0.99215686, 0.90588235, 0.14117647]],\n",
       "\n",
       "        [[0.30196078, 0.76078431, 0.41960784],\n",
       "         [0.21960784, 0.34117647, 0.54901961],\n",
       "         [0.16470588, 0.45882353, 0.55686275],\n",
       "         [0.18431373, 0.41176471, 0.55294118],\n",
       "         [0.21568627, 0.34901961, 0.54901961],\n",
       "         [0.14901961, 0.6745098 , 0.50588235]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xb, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 6, 6, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326 samples, validate on 141 samples\n",
      "Epoch 1/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.9635 - acc: 0.8006 - val_loss: 0.8003 - val_acc: 0.7305\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.6076 - acc: 0.7761 - val_loss: 0.6393 - val_acc: 0.7589\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.5306 - acc: 0.8006 - val_loss: 0.6064 - val_acc: 0.7660\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.4378 - acc: 0.8098 - val_loss: 0.5312 - val_acc: 0.8014\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.4265 - acc: 0.8098 - val_loss: 0.5413 - val_acc: 0.7801\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 0s 27us/step - loss: 0.4213 - acc: 0.8405 - val_loss: 0.5160 - val_acc: 0.8014\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.3725 - acc: 0.8374 - val_loss: 0.5350 - val_acc: 0.7801\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.3808 - acc: 0.8497 - val_loss: 0.5422 - val_acc: 0.7943\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.3372 - acc: 0.8589 - val_loss: 0.6132 - val_acc: 0.8156\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 0s 31us/step - loss: 0.3553 - acc: 0.8405 - val_loss: 0.5320 - val_acc: 0.7943\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.3182 - acc: 0.8681 - val_loss: 0.5888 - val_acc: 0.8085\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2735 - acc: 0.9018 - val_loss: 0.5756 - val_acc: 0.7660\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2736 - acc: 0.8834 - val_loss: 0.6010 - val_acc: 0.7872\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.4564 - acc: 0.8160 - val_loss: 0.7657 - val_acc: 0.7305\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.3410 - acc: 0.8834 - val_loss: 0.5286 - val_acc: 0.7801\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2752 - acc: 0.8926 - val_loss: 0.5668 - val_acc: 0.7589\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2502 - acc: 0.8988 - val_loss: 0.5899 - val_acc: 0.7730\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2586 - acc: 0.8957 - val_loss: 0.8382 - val_acc: 0.7872\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.3100 - acc: 0.8742 - val_loss: 0.6128 - val_acc: 0.7660\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2405 - acc: 0.9110 - val_loss: 0.8999 - val_acc: 0.7872\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.3807 - acc: 0.8282 - val_loss: 0.6095 - val_acc: 0.7801\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 0s 26us/step - loss: 0.3026 - acc: 0.8804 - val_loss: 0.5514 - val_acc: 0.7518\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 0s 31us/step - loss: 0.2384 - acc: 0.9264 - val_loss: 0.6384 - val_acc: 0.7730\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.2161 - acc: 0.9172 - val_loss: 0.6014 - val_acc: 0.7801\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - ETA: 0s - loss: 0.1801 - acc: 0.945 - 0s 28us/step - loss: 0.2358 - acc: 0.9141 - val_loss: 1.1325 - val_acc: 0.7589\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.4496 - acc: 0.8037 - val_loss: 0.5146 - val_acc: 0.7660\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - ETA: 0s - loss: 0.2879 - acc: 0.914 - 0s 25us/step - loss: 0.2414 - acc: 0.9202 - val_loss: 0.5916 - val_acc: 0.7518\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 0s 27us/step - loss: 0.2333 - acc: 0.9417 - val_loss: 0.6439 - val_acc: 0.7801\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2564 - acc: 0.8988 - val_loss: 0.7929 - val_acc: 0.7801\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2508 - acc: 0.8988 - val_loss: 0.6041 - val_acc: 0.7801\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1988 - acc: 0.9294 - val_loss: 0.6495 - val_acc: 0.7801\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2447 - acc: 0.8957 - val_loss: 1.5972 - val_acc: 0.6667\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.3817 - acc: 0.8681 - val_loss: 0.6070 - val_acc: 0.7660\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 0s 30us/step - loss: 0.1901 - acc: 0.9264 - val_loss: 0.7231 - val_acc: 0.7376\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1747 - acc: 0.9387 - val_loss: 0.7211 - val_acc: 0.7730\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1944 - acc: 0.9325 - val_loss: 0.9400 - val_acc: 0.7589\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2717 - acc: 0.8773 - val_loss: 0.6533 - val_acc: 0.7660\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2031 - acc: 0.9356 - val_loss: 0.7192 - val_acc: 0.7589\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1543 - acc: 0.9479 - val_loss: 0.7921 - val_acc: 0.7730\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2205 - acc: 0.9049 - val_loss: 1.7444 - val_acc: 0.6879\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.4118 - acc: 0.8466 - val_loss: 0.7372 - val_acc: 0.7518\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1661 - acc: 0.9509 - val_loss: 0.7997 - val_acc: 0.7589\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1555 - acc: 0.9509 - val_loss: 0.9141 - val_acc: 0.7518\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.3104 - acc: 0.8497 - val_loss: 0.6365 - val_acc: 0.7660\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1701 - acc: 0.9509 - val_loss: 0.7646 - val_acc: 0.7305\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1473 - acc: 0.9571 - val_loss: 0.7852 - val_acc: 0.7660\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2007 - acc: 0.9141 - val_loss: 1.4552 - val_acc: 0.7163\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.3824 - acc: 0.8589 - val_loss: 0.7046 - val_acc: 0.7376\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1551 - acc: 0.9448 - val_loss: 0.8207 - val_acc: 0.7376\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1341 - acc: 0.9479 - val_loss: 0.9140 - val_acc: 0.7518\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1489 - acc: 0.9417 - val_loss: 0.8091 - val_acc: 0.7589\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1737 - acc: 0.9417 - val_loss: 1.3389 - val_acc: 0.7376\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2687 - acc: 0.8988 - val_loss: 0.7885 - val_acc: 0.7518\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1461 - acc: 0.9632 - val_loss: 0.8499 - val_acc: 0.7589\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1506 - acc: 0.9417 - val_loss: 0.8782 - val_acc: 0.7589\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 0s 27us/step - loss: 0.4732 - acc: 0.8160 - val_loss: 0.6992 - val_acc: 0.7376\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1707 - acc: 0.9448 - val_loss: 0.8066 - val_acc: 0.7447\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1416 - acc: 0.9601 - val_loss: 0.8637 - val_acc: 0.7447\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1199 - acc: 0.9571 - val_loss: 0.9026 - val_acc: 0.7518\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1273 - acc: 0.9540 - val_loss: 0.8582 - val_acc: 0.7518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1651 - acc: 0.9356 - val_loss: 1.0938 - val_acc: 0.7376\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.2096 - acc: 0.9049 - val_loss: 0.8018 - val_acc: 0.7305\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2299 - acc: 0.9080 - val_loss: 0.7405 - val_acc: 0.7447\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.1341 - acc: 0.9540 - val_loss: 0.8859 - val_acc: 0.7801\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1239 - acc: 0.9693 - val_loss: 0.8944 - val_acc: 0.7447\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.3533 - acc: 0.8558 - val_loss: 1.0042 - val_acc: 0.7518\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1989 - acc: 0.9387 - val_loss: 0.7629 - val_acc: 0.7518\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1314 - acc: 0.9693 - val_loss: 0.8776 - val_acc: 0.7730\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1253 - acc: 0.9540 - val_loss: 0.9382 - val_acc: 0.7518\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1167 - acc: 0.9540 - val_loss: 0.9196 - val_acc: 0.7376\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 0s 27us/step - loss: 0.1254 - acc: 0.9601 - val_loss: 1.2584 - val_acc: 0.7730\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.5720 - acc: 0.8067 - val_loss: 0.7834 - val_acc: 0.7518\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1396 - acc: 0.9663 - val_loss: 0.8881 - val_acc: 0.7518\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1294 - acc: 0.9540 - val_loss: 0.8565 - val_acc: 0.7518\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1180 - acc: 0.9632 - val_loss: 0.8812 - val_acc: 0.7589\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.1074 - acc: 0.9663 - val_loss: 0.9404 - val_acc: 0.7518\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1140 - acc: 0.9693 - val_loss: 0.8950 - val_acc: 0.7376\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.2685 - acc: 0.9049 - val_loss: 1.6202 - val_acc: 0.6950\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.3684 - acc: 0.8620 - val_loss: 0.7642 - val_acc: 0.7660\n",
      "Epoch 80/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1298 - acc: 0.9693 - val_loss: 0.7880 - val_acc: 0.7376\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1167 - acc: 0.9663 - val_loss: 0.8985 - val_acc: 0.7730\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1053 - acc: 0.9755 - val_loss: 0.9352 - val_acc: 0.7730\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1036 - acc: 0.9693 - val_loss: 0.8776 - val_acc: 0.7660\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1926 - acc: 0.9202 - val_loss: 1.6507 - val_acc: 0.7021\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.3296 - acc: 0.8804 - val_loss: 0.8380 - val_acc: 0.7518\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1141 - acc: 0.9724 - val_loss: 0.9863 - val_acc: 0.7447\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1111 - acc: 0.9663 - val_loss: 0.9629 - val_acc: 0.7660\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0988 - acc: 0.9693 - val_loss: 0.9592 - val_acc: 0.7730\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0958 - acc: 0.9816 - val_loss: 0.9897 - val_acc: 0.7730\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0907 - acc: 0.9816 - val_loss: 1.0214 - val_acc: 0.7589\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.1016 - acc: 0.9724 - val_loss: 1.1746 - val_acc: 0.6809\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 0s 27us/step - loss: 0.6491 - acc: 0.7914 - val_loss: 0.7937 - val_acc: 0.7589\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1347 - acc: 0.9816 - val_loss: 0.8689 - val_acc: 0.7660\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1113 - acc: 0.9847 - val_loss: 0.9266 - val_acc: 0.7730\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0948 - acc: 0.9693 - val_loss: 0.9616 - val_acc: 0.7660\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0941 - acc: 0.9785 - val_loss: 1.0469 - val_acc: 0.7518\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1315 - acc: 0.9509 - val_loss: 0.9842 - val_acc: 0.7589\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2707 - acc: 0.8926 - val_loss: 1.6265 - val_acc: 0.6950\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.3036 - acc: 0.9018 - val_loss: 0.8684 - val_acc: 0.7518\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1102 - acc: 0.9755 - val_loss: 0.9469 - val_acc: 0.7518\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0929 - acc: 0.9785 - val_loss: 1.0380 - val_acc: 0.7518\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0981 - acc: 0.9755 - val_loss: 1.0909 - val_acc: 0.7518\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0982 - acc: 0.9724 - val_loss: 1.0068 - val_acc: 0.7447\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0994 - acc: 0.9785 - val_loss: 1.1042 - val_acc: 0.7447\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0960 - acc: 0.9663 - val_loss: 0.9709 - val_acc: 0.7305\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.4462 - acc: 0.8190 - val_loss: 0.8086 - val_acc: 0.7447\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1359 - acc: 0.9785 - val_loss: 0.8861 - val_acc: 0.7447\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.1050 - acc: 0.9816 - val_loss: 0.9868 - val_acc: 0.7660\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0968 - acc: 0.9785 - val_loss: 0.9859 - val_acc: 0.7730\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0877 - acc: 0.9816 - val_loss: 1.0230 - val_acc: 0.7660\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0907 - acc: 0.9755 - val_loss: 0.9951 - val_acc: 0.7305\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.3145 - acc: 0.8558 - val_loss: 1.4444 - val_acc: 0.7163\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.2355 - acc: 0.9141 - val_loss: 0.9042 - val_acc: 0.7589\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1080 - acc: 0.9755 - val_loss: 1.0211 - val_acc: 0.7518\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0945 - acc: 0.9785 - val_loss: 1.0672 - val_acc: 0.7518\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0892 - acc: 0.9847 - val_loss: 1.0363 - val_acc: 0.7589\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0811 - acc: 0.9939 - val_loss: 1.0803 - val_acc: 0.7730\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0756 - acc: 0.9877 - val_loss: 1.1150 - val_acc: 0.7589\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0749 - acc: 0.9877 - val_loss: 1.0807 - val_acc: 0.7730\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2382 - acc: 0.9172 - val_loss: 1.9723 - val_acc: 0.6525\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.3833 - acc: 0.8834 - val_loss: 0.8577 - val_acc: 0.7518\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1027 - acc: 0.9785 - val_loss: 0.9893 - val_acc: 0.7518\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0892 - acc: 0.9785 - val_loss: 1.0234 - val_acc: 0.7589\n",
      "Epoch 124/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0818 - acc: 0.9877 - val_loss: 1.0497 - val_acc: 0.7518\n",
      "Epoch 125/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0772 - acc: 0.9908 - val_loss: 1.0789 - val_acc: 0.7518\n",
      "Epoch 126/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0799 - acc: 0.9877 - val_loss: 1.1160 - val_acc: 0.7447\n",
      "Epoch 127/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0849 - acc: 0.9816 - val_loss: 1.1186 - val_acc: 0.7589\n",
      "Epoch 128/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0738 - acc: 0.9939 - val_loss: 1.2743 - val_acc: 0.7589\n",
      "Epoch 129/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2977 - acc: 0.9110 - val_loss: 1.7731 - val_acc: 0.6383\n",
      "Epoch 130/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.5780 - acc: 0.8650 - val_loss: 0.8776 - val_acc: 0.7589\n",
      "Epoch 131/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0963 - acc: 0.9908 - val_loss: 0.9415 - val_acc: 0.7589\n",
      "Epoch 132/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0850 - acc: 0.9939 - val_loss: 0.9770 - val_acc: 0.7589\n",
      "Epoch 133/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0791 - acc: 0.9877 - val_loss: 1.0106 - val_acc: 0.7660\n",
      "Epoch 134/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0726 - acc: 0.9969 - val_loss: 1.1069 - val_acc: 0.7589\n",
      "Epoch 135/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0848 - acc: 0.9816 - val_loss: 1.0701 - val_acc: 0.7518\n",
      "Epoch 136/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0701 - acc: 0.9939 - val_loss: 1.1838 - val_acc: 0.7589\n",
      "Epoch 137/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.1670 - acc: 0.9417 - val_loss: 1.3600 - val_acc: 0.6312\n",
      "Epoch 138/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.5217 - acc: 0.8006 - val_loss: 0.8349 - val_acc: 0.7376\n",
      "Epoch 139/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.1061 - acc: 0.9816 - val_loss: 0.9581 - val_acc: 0.7660\n",
      "Epoch 140/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.0853 - acc: 0.9939 - val_loss: 1.0590 - val_acc: 0.7660\n",
      "Epoch 141/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0857 - acc: 0.9816 - val_loss: 1.0922 - val_acc: 0.7660\n",
      "Epoch 142/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0744 - acc: 0.9908 - val_loss: 1.0974 - val_acc: 0.7730\n",
      "Epoch 143/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0723 - acc: 0.9908 - val_loss: 1.1138 - val_acc: 0.7589\n",
      "Epoch 144/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.0694 - acc: 0.9969 - val_loss: 1.1556 - val_acc: 0.7660\n",
      "Epoch 145/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0618 - acc: 0.9969 - val_loss: 1.2353 - val_acc: 0.7589\n",
      "Epoch 146/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0699 - acc: 0.9939 - val_loss: 1.0927 - val_acc: 0.7447\n",
      "Epoch 147/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.7351 - acc: 0.7945 - val_loss: 1.0387 - val_acc: 0.7376\n",
      "Epoch 148/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.1256 - acc: 0.9755 - val_loss: 0.9249 - val_acc: 0.7589\n",
      "Epoch 149/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0905 - acc: 0.9939 - val_loss: 1.0030 - val_acc: 0.7589\n",
      "Epoch 150/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0796 - acc: 0.9939 - val_loss: 1.0414 - val_acc: 0.7660\n",
      "Epoch 151/200\n",
      "326/326 [==============================] - 0s 22us/step - loss: 0.0751 - acc: 0.9939 - val_loss: 1.0878 - val_acc: 0.7589\n",
      "Epoch 152/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0676 - acc: 0.9939 - val_loss: 1.1063 - val_acc: 0.7660\n",
      "Epoch 153/200\n",
      "326/326 [==============================] - 0s 22us/step - loss: 0.0663 - acc: 0.9939 - val_loss: 1.0632 - val_acc: 0.7518\n",
      "Epoch 154/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0733 - acc: 0.9939 - val_loss: 1.1120 - val_acc: 0.7589\n",
      "Epoch 155/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0697 - acc: 0.9939 - val_loss: 1.2983 - val_acc: 0.7447\n",
      "Epoch 156/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2733 - acc: 0.9202 - val_loss: 1.0103 - val_acc: 0.7092\n",
      "Epoch 157/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.1577 - acc: 0.9417 - val_loss: 0.9999 - val_acc: 0.7660\n",
      "Epoch 158/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0812 - acc: 0.9969 - val_loss: 1.0883 - val_acc: 0.7730\n",
      "Epoch 159/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0690 - acc: 0.9939 - val_loss: 1.1419 - val_acc: 0.7730\n",
      "Epoch 160/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0702 - acc: 0.9908 - val_loss: 1.1533 - val_acc: 0.7730\n",
      "Epoch 161/200\n",
      "326/326 [==============================] - 0s 21us/step - loss: 0.0651 - acc: 0.9939 - val_loss: 1.2682 - val_acc: 0.7518\n",
      "Epoch 162/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.1000 - acc: 0.9724 - val_loss: 1.5198 - val_acc: 0.6667\n",
      "Epoch 163/200\n",
      "326/326 [==============================] - 0s 27us/step - loss: 0.6095 - acc: 0.8190 - val_loss: 0.9759 - val_acc: 0.7660\n",
      "Epoch 164/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0836 - acc: 0.9908 - val_loss: 1.0635 - val_acc: 0.7660\n",
      "Epoch 165/200\n",
      "326/326 [==============================] - 0s 27us/step - loss: 0.0768 - acc: 0.9939 - val_loss: 1.1158 - val_acc: 0.7660\n",
      "Epoch 166/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0629 - acc: 0.9939 - val_loss: 1.1655 - val_acc: 0.7660\n",
      "Epoch 167/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0587 - acc: 0.9939 - val_loss: 1.1906 - val_acc: 0.7730\n",
      "Epoch 168/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0597 - acc: 0.9939 - val_loss: 1.2413 - val_acc: 0.7589\n",
      "Epoch 169/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0888 - acc: 0.9847 - val_loss: 1.2057 - val_acc: 0.7305\n",
      "Epoch 170/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.1378 - acc: 0.9479 - val_loss: 1.4706 - val_acc: 0.7234\n",
      "Epoch 171/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.2055 - acc: 0.9264 - val_loss: 0.9429 - val_acc: 0.7589\n",
      "Epoch 172/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0824 - acc: 0.9969 - val_loss: 1.1353 - val_acc: 0.7589\n",
      "Epoch 173/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0665 - acc: 0.9939 - val_loss: 1.1224 - val_acc: 0.7518\n",
      "Epoch 174/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0629 - acc: 0.9969 - val_loss: 1.2165 - val_acc: 0.7660\n",
      "Epoch 175/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.0658 - acc: 0.9908 - val_loss: 1.3134 - val_acc: 0.7518\n",
      "Epoch 176/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.3733 - acc: 0.9049 - val_loss: 1.0234 - val_acc: 0.7234\n",
      "Epoch 177/200\n",
      "326/326 [==============================] - 0s 27us/step - loss: 0.0885 - acc: 0.9785 - val_loss: 1.1550 - val_acc: 0.7518\n",
      "Epoch 178/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0650 - acc: 0.9908 - val_loss: 1.1602 - val_acc: 0.7589\n",
      "Epoch 179/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0579 - acc: 0.9969 - val_loss: 1.2048 - val_acc: 0.7660\n",
      "Epoch 180/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0607 - acc: 0.9908 - val_loss: 1.1944 - val_acc: 0.7660\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 0s 24us/step - loss: 0.0602 - acc: 0.9969 - val_loss: 1.2456 - val_acc: 0.7660\n",
      "Epoch 182/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0628 - acc: 0.9939 - val_loss: 1.4974 - val_acc: 0.7518\n",
      "Epoch 183/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.3516 - acc: 0.8589 - val_loss: 0.9963 - val_acc: 0.7518\n",
      "Epoch 184/200\n",
      "326/326 [==============================] - 0s 27us/step - loss: 0.1002 - acc: 0.9785 - val_loss: 1.0522 - val_acc: 0.7376\n",
      "Epoch 185/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0652 - acc: 0.9939 - val_loss: 1.1262 - val_acc: 0.7589\n",
      "Epoch 186/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0592 - acc: 0.9969 - val_loss: 1.1818 - val_acc: 0.7660\n",
      "Epoch 187/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0604 - acc: 0.9969 - val_loss: 1.2509 - val_acc: 0.7660\n",
      "Epoch 188/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0507 - acc: 0.9939 - val_loss: 1.2256 - val_acc: 0.7589\n",
      "Epoch 189/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.0629 - acc: 0.9939 - val_loss: 1.2604 - val_acc: 0.7589\n",
      "Epoch 190/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0560 - acc: 0.9969 - val_loss: 1.5266 - val_acc: 0.7660\n",
      "Epoch 191/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.7285 - acc: 0.7791 - val_loss: 0.9771 - val_acc: 0.7447\n",
      "Epoch 192/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0788 - acc: 0.9969 - val_loss: 1.0511 - val_acc: 0.7660\n",
      "Epoch 193/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.0700 - acc: 0.9969 - val_loss: 1.1042 - val_acc: 0.7660\n",
      "Epoch 194/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0609 - acc: 0.9969 - val_loss: 1.1654 - val_acc: 0.7660\n",
      "Epoch 195/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0623 - acc: 0.9969 - val_loss: 1.2111 - val_acc: 0.7660\n",
      "Epoch 196/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0543 - acc: 0.9969 - val_loss: 1.1988 - val_acc: 0.7518\n",
      "Epoch 197/200\n",
      "326/326 [==============================] - 0s 28us/step - loss: 0.0611 - acc: 0.9969 - val_loss: 1.2219 - val_acc: 0.7518\n",
      "Epoch 198/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0524 - acc: 0.9969 - val_loss: 1.2947 - val_acc: 0.7589\n",
      "Epoch 199/200\n",
      "326/326 [==============================] - 0s 25us/step - loss: 0.0615 - acc: 0.9877 - val_loss: 1.2163 - val_acc: 0.7660\n",
      "Epoch 200/200\n",
      "326/326 [==============================] - 0s 24us/step - loss: 0.0550 - acc: 0.9969 - val_loss: 1.3107 - val_acc: 0.7589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d82399ba8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=200, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 15us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9859883322644589, 0.7810945252874004]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)\n",
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.predict(X_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.3511391e-04],\n",
       "       [9.9999825e+01],\n",
       "       [2.0805001e-02],\n",
       "       [3.5634637e-02],\n",
       "       [9.9999771e+01],\n",
       "       [9.9983879e+01],\n",
       "       [2.2825599e-02],\n",
       "       [8.1753731e-02],\n",
       "       [9.0052284e+01],\n",
       "       [2.3841858e-05],\n",
       "       [9.9206337e+01],\n",
       "       [1.7373264e-01],\n",
       "       [1.4603138e-04],\n",
       "       [4.0975213e-02],\n",
       "       [9.5878326e+01],\n",
       "       [4.2093992e-01],\n",
       "       [3.1411648e-03],\n",
       "       [1.8054515e+00],\n",
       "       [1.7881393e-05],\n",
       "       [9.9998734e+01],\n",
       "       [8.3446503e-05],\n",
       "       [0.0000000e+00],\n",
       "       [7.5296577e+01],\n",
       "       [7.1168579e+01],\n",
       "       [9.9662262e+01],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [4.7233105e-01],\n",
       "       [2.9090912e+01],\n",
       "       [9.9810318e+01],\n",
       "       [5.2756369e-01],\n",
       "       [9.0553490e+01],\n",
       "       [6.3902438e-01],\n",
       "       [4.4405460e-04],\n",
       "       [9.9841118e+01],\n",
       "       [4.6212375e-01],\n",
       "       [9.4842315e-01],\n",
       "       [1.4603138e-03],\n",
       "       [9.9985161e+01],\n",
       "       [2.2475117e+01],\n",
       "       [8.9544058e-02],\n",
       "       [3.5166740e-04],\n",
       "       [9.9568123e+01],\n",
       "       [9.9717583e+01],\n",
       "       [9.1849566e-01],\n",
       "       [9.8589600e+01],\n",
       "       [9.8443375e+01],\n",
       "       [4.9307346e-01],\n",
       "       [7.6765038e+01],\n",
       "       [7.6875153e+01],\n",
       "       [1.4922899e+01],\n",
       "       [3.3944845e-03],\n",
       "       [8.6913109e-01],\n",
       "       [9.9509979e+01],\n",
       "       [7.7486038e-05],\n",
       "       [2.2694468e-02],\n",
       "       [7.0405006e-02],\n",
       "       [9.9996460e+01],\n",
       "       [6.4932406e-01],\n",
       "       [1.7911196e-02],\n",
       "       [9.8381714e+01],\n",
       "       [2.3841858e-05],\n",
       "       [1.2293071e+00],\n",
       "       [5.8041513e-01],\n",
       "       [6.8545341e-05],\n",
       "       [1.7443210e+00],\n",
       "       [9.7468277e+01],\n",
       "       [9.7798172e+01],\n",
       "       [1.5869617e+00],\n",
       "       [2.6881695e-03],\n",
       "       [6.4859986e-01],\n",
       "       [9.6006416e+01],\n",
       "       [9.6653625e+01],\n",
       "       [6.9528818e-03],\n",
       "       [6.0075223e-01],\n",
       "       [9.9673866e+01],\n",
       "       [9.9039352e+01],\n",
       "       [3.0909181e-01],\n",
       "       [9.0990288e+01],\n",
       "       [4.3040514e-01],\n",
       "       [9.9980888e+01],\n",
       "       [9.9837723e+01],\n",
       "       [1.1227459e+00],\n",
       "       [9.9921593e+01],\n",
       "       [2.1166302e+01],\n",
       "       [5.2177906e-02],\n",
       "       [2.9802322e-06],\n",
       "       [2.3422837e-01],\n",
       "       [1.5453398e-01],\n",
       "       [6.8497956e-01],\n",
       "       [9.8351929e+01],\n",
       "       [1.1216402e-01],\n",
       "       [7.5023178e+01],\n",
       "       [3.7293673e+00],\n",
       "       [1.1413962e+00],\n",
       "       [1.0697666e+01],\n",
       "       [9.0493942e+01],\n",
       "       [0.0000000e+00],\n",
       "       [9.6744850e+01],\n",
       "       [9.7650742e+01],\n",
       "       [1.0336637e+00],\n",
       "       [9.6634140e+01],\n",
       "       [1.7285347e-04],\n",
       "       [2.9802322e-06],\n",
       "       [7.9542398e-03],\n",
       "       [1.1994481e+00],\n",
       "       [9.9927971e+01],\n",
       "       [5.6580603e-01],\n",
       "       [9.9954750e+01],\n",
       "       [2.5177002e-02],\n",
       "       [4.1860342e-02],\n",
       "       [9.9793610e+01],\n",
       "       [1.7881393e-05],\n",
       "       [9.9999931e+01],\n",
       "       [9.9902306e+01],\n",
       "       [2.2441149e-03],\n",
       "       [0.0000000e+00],\n",
       "       [2.5897026e+01],\n",
       "       [6.6369772e-03],\n",
       "       [9.9980286e+01],\n",
       "       [2.2932081e+00],\n",
       "       [7.1674585e-02],\n",
       "       [4.7640419e+01],\n",
       "       [5.0715208e-01],\n",
       "       [8.3178009e+01],\n",
       "       [6.2584877e-03],\n",
       "       [2.9775500e-02],\n",
       "       [9.9931511e+01],\n",
       "       [9.7348442e+01],\n",
       "       [9.6645951e-02],\n",
       "       [9.9999619e+01],\n",
       "       [9.5963478e-04],\n",
       "       [6.3359737e-03],\n",
       "       [9.8841393e+01],\n",
       "       [8.3684921e-02],\n",
       "       [9.9998329e+01],\n",
       "       [9.9446014e+01],\n",
       "       [7.7664852e-03],\n",
       "       [5.4347843e+01],\n",
       "       [9.9999573e+01],\n",
       "       [9.3800644e+01],\n",
       "       [4.5078516e+00],\n",
       "       [9.9022507e+01],\n",
       "       [9.9733322e+01],\n",
       "       [1.5129924e+00],\n",
       "       [9.9752724e+01],\n",
       "       [9.9840820e+01],\n",
       "       [5.0663948e-05],\n",
       "       [8.9406967e-06],\n",
       "       [9.9810966e+01],\n",
       "       [2.9228330e-01],\n",
       "       [9.9900780e+01],\n",
       "       [3.1885803e-01],\n",
       "       [9.9919533e+01],\n",
       "       [9.9948837e+01],\n",
       "       [4.0531158e-04],\n",
       "       [9.9679214e+01],\n",
       "       [1.2025237e-02],\n",
       "       [9.9841980e+01],\n",
       "       [9.9353699e+01],\n",
       "       [6.0200691e-04],\n",
       "       [7.2091818e-03],\n",
       "       [9.9999252e+01],\n",
       "       [2.1696091e-03],\n",
       "       [9.9542213e+01],\n",
       "       [9.9943268e+01],\n",
       "       [9.9999847e+01],\n",
       "       [1.4901161e-05],\n",
       "       [2.2649765e-04],\n",
       "       [3.2730460e+00],\n",
       "       [9.9709488e+01],\n",
       "       [7.2419643e-04],\n",
       "       [9.1893375e-01],\n",
       "       [1.0451674e-02],\n",
       "       [5.2744150e-02],\n",
       "       [9.9999992e+01],\n",
       "       [9.9770714e+01],\n",
       "       [9.9221985e+01],\n",
       "       [5.9604645e-06],\n",
       "       [6.4969063e-04],\n",
       "       [9.9743690e+01],\n",
       "       [9.9881317e+01],\n",
       "       [2.0861626e-05],\n",
       "       [9.6976875e+01],\n",
       "       [1.0000000e+02],\n",
       "       [1.2218952e-03],\n",
       "       [8.2552433e-04],\n",
       "       [5.9179454e+00],\n",
       "       [2.8855534e+00],\n",
       "       [3.4691393e-01],\n",
       "       [1.2254715e-01],\n",
       "       [9.3057884e+01],\n",
       "       [1.0000000e+02],\n",
       "       [1.3820142e+00],\n",
       "       [9.7222504e+01],\n",
       "       [9.6448029e+01],\n",
       "       [2.5609136e-02],\n",
       "       [9.9446571e+01],\n",
       "       [2.4646521e-03],\n",
       "       [1.1948049e+00],\n",
       "       [2.2291491e+00]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
